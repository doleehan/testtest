{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-695051675e85>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# 데이터 분석\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mrandom\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mrnd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# 데이터 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 기계 학습\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview tail of the data\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "print('_'*40)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in train dataset\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 속성에 값이 없는 샘플들이 존재. 그 중 Age, Cabin에 missing value(누락값)가 많이 발견됨 전체에서 몇프로나 차지하는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age에 누락값이 있는 샘플의 비율\n",
    "sum(pd.isnull(train_df['Age']))/len(train_df[\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin에 누락값이 있는 샘플의 비율\n",
    "sum(pd.isnull(train_df['Cabin']))/len(train_df[\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Age는 20%의 샘플에서 누락, Cabin은 77%의 샘플에서 누락. Age는 누락된 값을 채워넣고, Cabin은 아예 feature를 버리는게 낫겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age가 어떻게 분포되어 있는지 히스토그램으로 확인해보자.\n",
    "ax = train_df[\"Age\"].hist(bins=15, color='teal', alpha=0.8)\n",
    "ax.set(xlabel='Age', ylabel='Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그럼 Age의 중간값은 얼마일까?\n",
    "train_df['Age'].median(skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 누락된 값들에 그냥 중간값을 일괄적으로 채워넣는 것이 좋아보인다. 남은 것은 train에서 Embarked, test에서 Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에서 Embarked 의 분포를 확인해보자.\n",
    "sns.countplot(x='Embarked',data=train_df,palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fare는 가격, 그럼 평균값은?\n",
    "train_df[\"Fare\"].mean(skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Embarked는 S가 가장 많으니 누락값에 S를 채워넣으면 무난하겠다.\n",
    "###### Fare는 승선한 항구와 티켓 등급에 따라 다르겠지만 편이상 평균값인 32를 취해서 누락값에 넣는 것을 채택하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리: 속성에 따라 누락된 값을 채워 넣거나 속성 자체 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 값을 적절한 값으로 채워넣기\n",
    "train_df[\"Age\"].fillna(28, inplace=True)\n",
    "test_df[\"Age\"].fillna(28, inplace=True)\n",
    "train_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "test_df[\"Fare\"].fillna(32, inplace=True)\n",
    "# 누락된 값이 너무 많은 속성 제거\n",
    "train_df.drop('Cabin', axis=1, inplace=True)\n",
    "test_df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 속성별 값에 따라 생존자 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객실 등급에 따른 생존자 확률\n",
    "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성별에 따른 생존자 확률\n",
    "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가족, 친척의 명수에 따른 생존자 확률\n",
    "train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모자식 관계에 있는 사람의 명수에 따른 생존자 확률\n",
    "train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이별 비생존자와 생존자\n",
    "g = sns.FacetGrid(train_df, col='Survived') # 열에 생존자 0/1 \n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이별 객실 등급별 비생존자와 생존자\n",
    "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6) # 열에 생존자, 행에 객실 등급 \n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이번에는 히스토그램이 아닌 꺾은선 그래프\n",
    "grid = sns.FacetGrid(train_df, col='Embarked', size=2.2, aspect=1.6)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep', order=[1, 2, 3], hue_order=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리: 속성 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선 현재 보유하고 있는 속성을 다시 한 번 확인해보자\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 속성 조정\n",
    "1. PassengerId는 샘플별로 다르기 때문에 제거\n",
    "2. Survived 는 예측해야할 output\n",
    "3. Age, Fare는 그대로 채택\n",
    "4. Sex, Pclass, Embarked는 카테고리 값이므로 처리.\n",
    "5. SibSp, Parch 는 Binary 값으로 수정\n",
    "6. Ticket은 표 번호이므로 상관성이 거의 없는 값이라 제거\n",
    "7. Name은 한 번 살펴볼 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 : 속성 조정 - SibSp, Parch 는 Binary 값으로 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신규 속성인 TravelSibSp, TravelParch 만들어줌\n",
    "# 해당 속성이 0보다 크면 1, 아니면 0\n",
    "train_df['TravelSibSp'] = np.where(train_df['SibSp']>0, 1, 0)\n",
    "train_df['TravelParch'] = np.where(train_df['Parch']>0, 1, 0)\n",
    "# 이후 SibSp, SibSp 제거\n",
    "train_df.drop('SibSp', axis=1, inplace=True)\n",
    "train_df.drop('Parch', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터도 마찬가지로 적용\n",
    "test_df['TravelSibSp'] = np.where(test_df['SibSp']>0, 1, 0)\n",
    "test_df['TravelParch'] = np.where(test_df['Parch']>0, 1, 0)\n",
    "test_df.drop('SibSp', axis=1, inplace=True)\n",
    "test_df.drop('Parch', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 : 속성 조정 - 카테고리 속성인 Pclass, Embarked, Sex 처리\n",
    "\n",
    "어떻게? Pclass에 세 가지가 있으니 Pclass 라는 속성을 세 개로 쪼갠다. Pclass_1, Pclass_2, Pclass_3\n",
    "\n",
    "Embarked도 마찬가지. S, C, Q 가 있으니 Embarked_S, Embarked_C, Embarked_Q\n",
    "\n",
    "Sex도 마찬가지, female, male 이 있으니 Sex_female, Sex_femal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pcalss를 위한 새로운 카테고리 속성을 만들어 새롭게 저장 (train_df2)\n",
    "train_df2 = pd.get_dummies(train_df, columns=[\"Pclass\"])\n",
    "\n",
    "# Embarked를 위한 새로운 카테고리 속성을 만들어 새롭게 저장 (train_df3)\n",
    "train_df3 = pd.get_dummies(train_df, columns=[\"Embarked\"])\n",
    "\n",
    "# Sex를 위한 새로운 카테고리 속성을 만들어 새롭게 저장 (train_df3)\n",
    "train_df4 = pd.get_dummies(train_df, columns=[\"Sex\"])\n",
    "\n",
    "# 결과 확인\n",
    "train_df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 그런데 여기서, Sex_female, Sex_male 이 모두 필요할까? 어짜피 같은 정보를 갖고 있으므로 둘 중 하나만 있으면 되지 않는가? 따라서 둘 중 하나를 삭제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 : 속성 조정 - 쓸모없는 속성 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4.drop('PassengerId', axis=1, inplace=True)\n",
    "train_df4.drop('Name', axis=1, inplace=True)\n",
    "train_df4.drop('Ticket', axis=1, inplace=True)\n",
    "train_df4.drop('Sex_male', axis=1, inplace=True)\n",
    "train_df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 : 위의 속성 조정을 이젠 test_df에도 모두 해주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = pd.get_dummies(train_df, columns=[\"Pclass\"])\n",
    "train_df3 = pd.get_dummies(train_df2, columns=[\"Embarked\"])\n",
    "train_df4 = pd.get_dummies(train_df3, columns=[\"Sex\"])\n",
    "train_df4.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4.drop('PassengerId', axis=1, inplace=True) #<--- 이건 나중에 평가를 위해 일단 지금은 지우지 말자\n",
    "train_df4.drop('Name', axis=1, inplace=True)\n",
    "train_df4.drop('Ticket', axis=1, inplace=True)\n",
    "train_df4.drop('Sex_male', axis=1, inplace=True)\n",
    "train_df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2 = pd.get_dummies(test_df, columns=[\"Pclass\"])\n",
    "test_df3 = pd.get_dummies(test_df2, columns=[\"Embarked\"])\n",
    "test_df4 = pd.get_dummies(test_df3, columns=[\"Sex\"])\n",
    "#test_df4.drop('PassengerId', axis=1, inplace=True) <--- 이건 나중에 평가를 위해 일단 지금은 지우지 말자\n",
    "test_df4.drop('Name', axis=1, inplace=True)\n",
    "test_df4.drop('Ticket', axis=1, inplace=True)\n",
    "test_df4.drop('Sex_male', axis=1, inplace=True)\n",
    "test_df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 이제 드디어 데이터 준비는 모두 끝났다!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 기법을 활용한 생존자 예측\n",
    "## 활용 모델\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "k-Nearest Neighbors\n",
    "\n",
    "Support Vector Machines\n",
    "\n",
    "Naive Bayes classifier\n",
    "\n",
    "Decision Tree\n",
    "\n",
    "Artificial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선 학습 집합과 테스트 집합을 준비한다.\n",
    "X_train = train_df4.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df4[\"Survived\"]\n",
    "X_test = test_df4.drop(\"PassengerId\", axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM 모델 학습\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "# 테스트 데이터에 대해 예측\n",
    "Y_pred_svc = svc.predict(X_test)\n",
    "# 테스트 데이터를 현재 레이블이 없으므로 학습 데이터에 대해 예측한 정확도 측정\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression training\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression prediction\n",
    "Y_pred_logreg = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2) # training 데이터에 대해 예측 정확도 구함\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 속성별 상관 계수\n",
    "coeff_df  =  pd.DataFrame(train_df4.columns.delete(0))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn  = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred_NB = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred_DT = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train)*100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = MLPClassifier(solver='lbfgs', alpha=1, hidden_layer_sizes=(10, 30), random_state=1)\n",
    "ANN.fit(X_train, Y_train)\n",
    "Y_pred_ANN = ANN.predict(X_test)\n",
    "acc_ANN = round(ANN.score(X_train, Y_train) * 100, 2)\n",
    "acc_ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = Y_pred_DT\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df4[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}